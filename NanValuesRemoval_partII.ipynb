{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e59bff2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "import time\n",
    "import statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2d947a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model, metrics, model_selection, preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88e0f59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from scipy import sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d48f145d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ames clean dataset has size of :(1156, 59)\n"
     ]
    }
   ],
   "source": [
    "AmesClean = pd.read_csv('AmesCleanDataSet.csv')\n",
    "AmesClean.drop(['Unnamed: 0'],axis=1,inplace=True)\n",
    "print('Ames clean dataset has size of :' + str(AmesClean.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b72222c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.sum(AmesClean.isna()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e68a54e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "AmesClean['salePriceCat'] = pd.cut(AmesClean.SalePrice,bins=10,labels = range(10)).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "71e510ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = ['MS_SubClass','MS_Zoning','Lot_Shape','Land_Contour','Lot_Config','Land_Slope']\n",
    "categorical_features.extend(['Neighborhood','Condition_1','Bldg_Type','House_Style','Roof_Style'])\n",
    "categorical_features.extend(['Mas_Vnr_Type','Exter_Qual','Exter_Cond','Foundation','Bsmt_Qual','Bsmt_Exposure'])\n",
    "categorical_features.extend(['basement_type','Heating_QC','Garage_Finish','Mo_Sold','Sale_Type','Sale_Condition','Kitchen_Qual'])\n",
    "categorical_features.extend(['exterior','Fireplace_Qu','Garage_Type','Garage_Qual'])\n",
    "Ordinal_featues = ['Overall_Qual','Overall_Cond']\n",
    "Continous_features = ['Lot_Frontage','Lot_Area','age','remodeled_age','Mas_Vnr_Area','basement_area']\n",
    "Continous_features.extend(['Bsmt_Unf_SF','Total_Bsmt_SF','1st_Flr_SF','2nd_Flr_SF','Low_Qual_Fin_SF'])\n",
    "Continous_features.extend(['Gr_Liv_Area','Bsmt_Full_Bath','Bsmt_Half_Bath','Full_Bath','Half_Bath'])\n",
    "Continous_features.extend(['Bedroom_AbvGr','Kitchen_AbvGr','TotRms_AbvGrd','Fireplaces'])               \n",
    "Continous_features.extend(['Garage_Cars','Garage_Area'])\n",
    "Continous_features.extend(['Wood_Deck_SF','Open_Porch_SF','Enclosed_Porch','Screen_Porch','Pool_Area'])\n",
    "Continous_features.extend(['SalePrice','garage_age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f96b6011",
   "metadata": {},
   "outputs": [],
   "source": [
    "AmesCleanFinal = AmesClean.drop(categorical_features,axis=1)\n",
    "AmesCleanFinalSP = sparse.csr_matrix(AmesCleanFinal.values)\n",
    "AmesCleanColSP = AmesCleanFinal.columns\n",
    "\n",
    "for ifeature in categorical_features:\n",
    "    \n",
    "    temp_df = pd.get_dummies(AmesClean.loc[:,ifeature],prefix=ifeature,prefix_sep='_')\n",
    "    AmesCleanColSP = list(AmesCleanColSP) + list(temp_df.columns)\n",
    "    temp_data_sp = sparse.csr_matrix(temp_df.values)\n",
    "    AmesCleanFinalSP = sparse.hstack([AmesCleanFinalSP,temp_data_sp])\n",
    "    \n",
    "AmesCleanDumCleanSP = pd.DataFrame.sparse.from_spmatrix(AmesCleanFinalSP, columns = AmesCleanColSP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e832fff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of cleaned datanase in sparse mode is :(1156, 241)\n"
     ]
    }
   ],
   "source": [
    "print('The size of cleaned datanase in sparse mode is :' + str(AmesCleanDumCleanSP.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "568b76c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sp = AmesCleanDumCleanSP.drop(['SalePrice','salePriceCat'],axis=1)\n",
    "Y_sp = AmesCleanDumCleanSP.SalePrice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d64cd61",
   "metadata": {},
   "outputs": [],
   "source": [
    "AmesCleanFinal = AmesClean.drop(categorical_features,axis=1)\n",
    "AmesCleanFinalData = AmesCleanFinal.values\n",
    "AmesCleanCol = AmesCleanFinal.columns\n",
    "\n",
    "for ifeature in categorical_features:\n",
    "    \n",
    "    temp_df = pd.get_dummies(AmesClean.loc[:,ifeature],prefix=ifeature,prefix_sep='_')\n",
    "    AmesCleanCol = list(AmesCleanCol) + list(temp_df.columns)\n",
    "    temp_data = temp_df.values\n",
    "    AmesCleanFinalData = np.hstack([AmesCleanFinalData,temp_data])\n",
    "    \n",
    "AmesCleanDumClean = pd.DataFrame(AmesCleanFinalData, columns = AmesCleanCol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dc34c9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = AmesCleanDumClean.drop(['SalePrice','salePriceCat'],axis=1)\n",
    "Y = AmesCleanDumClean.SalePrice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2020249e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.211096390302861\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.getsizeof(X)/sys.getsizeof(X_sp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "828fa9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "df3a079b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5684346a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sp, X_test_sp, Y_train_sp, Y_test_sp = train_test_split(X_sp,Y_sp,test_size = 0.33,stratify = AmesCleanDumCleanSP.salePriceCat)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y,test_size = 0.33,stratify = AmesCleanDumClean.salePriceCat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a6ceadb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest_model = RandomForestRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a3ebce49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'ccp_alpha': 0.0,\n",
       " 'criterion': 'squared_error',\n",
       " 'max_depth': None,\n",
       " 'max_features': 'auto',\n",
       " 'max_leaf_nodes': None,\n",
       " 'max_samples': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 100,\n",
       " 'n_jobs': None,\n",
       " 'oob_score': False,\n",
       " 'random_state': None,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_forest_model.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0b38a5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8f7a659d",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest_model.set_params(n_jobs = -1,oob_score = True, random_state = 144)\n",
    "\n",
    "depth_list = np.arange(10,40,10)\n",
    "estimator_list = [int(10**i) for i in np.arange(2,4,1)]\n",
    "feature_list = np.arange(5,20,5)\n",
    "\n",
    "random_forest_params = {'max_depth':depth_list,'max_features':feature_list,'n_estimators':estimator_list}\n",
    "grid = GridSearchCV(random_forest_model,random_forest_params,cv=5,return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5d4fedc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1min 25s\n",
      "Wall time: 1min 20s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=RandomForestRegressor(n_jobs=-1, oob_score=True,\n",
       "                                             random_state=144),\n",
       "             param_grid={'max_depth': array([10, 20, 30]),\n",
       "                         'max_features': array([ 5, 10, 15]),\n",
       "                         'n_estimators': [100, 1000]},\n",
       "             return_train_score=True)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time grid.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e0d3dfdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'ccp_alpha': 0.0,\n",
       " 'criterion': 'squared_error',\n",
       " 'max_depth': None,\n",
       " 'max_features': 'auto',\n",
       " 'max_leaf_nodes': None,\n",
       " 'max_samples': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 100,\n",
       " 'n_jobs': -1,\n",
       " 'oob_score': True,\n",
       " 'random_state': 144,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_forest_model.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7d7da2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(grid.cv_results_).to_csv('GridSearchResult.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9849e929",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(max_depth=20, max_features=15, n_estimators=1000,\n",
       "                      n_jobs=-1, oob_score=True, random_state=144)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "38c93d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "df =pd.DataFrame(grid.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c6353828",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['mean_fit_time', 'std_fit_time', 'mean_score_time', 'std_score_time',\n",
       "       'param_max_depth', 'param_max_features', 'param_n_estimators', 'params',\n",
       "       'split0_test_score', 'split1_test_score', 'split2_test_score',\n",
       "       'split3_test_score', 'split4_test_score', 'mean_test_score',\n",
       "       'std_test_score', 'rank_test_score', 'split0_train_score',\n",
       "       'split1_train_score', 'split2_train_score', 'split3_train_score',\n",
       "       'split4_train_score', 'mean_train_score', 'std_train_score'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9e3442df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_max_features</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>0.799128</td>\n",
       "      <td>0.934519</td>\n",
       "      <td>0.037700</td>\n",
       "      <td>0.002906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.801454</td>\n",
       "      <td>0.937031</td>\n",
       "      <td>0.032371</td>\n",
       "      <td>0.002541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>0.831915</td>\n",
       "      <td>0.962288</td>\n",
       "      <td>0.041777</td>\n",
       "      <td>0.002370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.833716</td>\n",
       "      <td>0.962775</td>\n",
       "      <td>0.040748</td>\n",
       "      <td>0.002315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>100</td>\n",
       "      <td>0.845942</td>\n",
       "      <td>0.969762</td>\n",
       "      <td>0.046001</td>\n",
       "      <td>0.001323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.847454</td>\n",
       "      <td>0.970299</td>\n",
       "      <td>0.045034</td>\n",
       "      <td>0.002193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>0.814609</td>\n",
       "      <td>0.973331</td>\n",
       "      <td>0.033754</td>\n",
       "      <td>0.001582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.818609</td>\n",
       "      <td>0.974905</td>\n",
       "      <td>0.033475</td>\n",
       "      <td>0.001283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>0.835978</td>\n",
       "      <td>0.977731</td>\n",
       "      <td>0.042623</td>\n",
       "      <td>0.001889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.838909</td>\n",
       "      <td>0.978087</td>\n",
       "      <td>0.040982</td>\n",
       "      <td>0.001457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>20</td>\n",
       "      <td>15</td>\n",
       "      <td>100</td>\n",
       "      <td>0.844657</td>\n",
       "      <td>0.978465</td>\n",
       "      <td>0.047210</td>\n",
       "      <td>0.001384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>20</td>\n",
       "      <td>15</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.851241</td>\n",
       "      <td>0.979689</td>\n",
       "      <td>0.044108</td>\n",
       "      <td>0.001487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>30</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>0.817978</td>\n",
       "      <td>0.974127</td>\n",
       "      <td>0.032737</td>\n",
       "      <td>0.001335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>30</td>\n",
       "      <td>5</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.817716</td>\n",
       "      <td>0.975277</td>\n",
       "      <td>0.034486</td>\n",
       "      <td>0.001260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>0.837575</td>\n",
       "      <td>0.977854</td>\n",
       "      <td>0.038823</td>\n",
       "      <td>0.002088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.840340</td>\n",
       "      <td>0.978161</td>\n",
       "      <td>0.040334</td>\n",
       "      <td>0.001496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>30</td>\n",
       "      <td>15</td>\n",
       "      <td>100</td>\n",
       "      <td>0.842747</td>\n",
       "      <td>0.978341</td>\n",
       "      <td>0.046152</td>\n",
       "      <td>0.000977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>30</td>\n",
       "      <td>15</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.849988</td>\n",
       "      <td>0.979634</td>\n",
       "      <td>0.043414</td>\n",
       "      <td>0.001553</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_max_depth param_max_features param_n_estimators  mean_test_score  \\\n",
       "0               10                  5                100         0.799128   \n",
       "1               10                  5               1000         0.801454   \n",
       "2               10                 10                100         0.831915   \n",
       "3               10                 10               1000         0.833716   \n",
       "4               10                 15                100         0.845942   \n",
       "5               10                 15               1000         0.847454   \n",
       "6               20                  5                100         0.814609   \n",
       "7               20                  5               1000         0.818609   \n",
       "8               20                 10                100         0.835978   \n",
       "9               20                 10               1000         0.838909   \n",
       "10              20                 15                100         0.844657   \n",
       "11              20                 15               1000         0.851241   \n",
       "12              30                  5                100         0.817978   \n",
       "13              30                  5               1000         0.817716   \n",
       "14              30                 10                100         0.837575   \n",
       "15              30                 10               1000         0.840340   \n",
       "16              30                 15                100         0.842747   \n",
       "17              30                 15               1000         0.849988   \n",
       "\n",
       "    mean_train_score  std_test_score  std_train_score  \n",
       "0           0.934519        0.037700         0.002906  \n",
       "1           0.937031        0.032371         0.002541  \n",
       "2           0.962288        0.041777         0.002370  \n",
       "3           0.962775        0.040748         0.002315  \n",
       "4           0.969762        0.046001         0.001323  \n",
       "5           0.970299        0.045034         0.002193  \n",
       "6           0.973331        0.033754         0.001582  \n",
       "7           0.974905        0.033475         0.001283  \n",
       "8           0.977731        0.042623         0.001889  \n",
       "9           0.978087        0.040982         0.001457  \n",
       "10          0.978465        0.047210         0.001384  \n",
       "11          0.979689        0.044108         0.001487  \n",
       "12          0.974127        0.032737         0.001335  \n",
       "13          0.975277        0.034486         0.001260  \n",
       "14          0.977854        0.038823         0.002088  \n",
       "15          0.978161        0.040334         0.001496  \n",
       "16          0.978341        0.046152         0.000977  \n",
       "17          0.979634        0.043414         0.001553  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[:,['param_max_depth','param_max_features','param_n_estimators','mean_test_score','mean_train_score','std_test_score',\n",
    "          'std_train_score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "db100f19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mean_fit_time                                                  0.239961\n",
       "std_fit_time                                                   0.014151\n",
       "mean_score_time                                                0.026745\n",
       "std_score_time                                                  0.00233\n",
       "param_max_depth                                                      20\n",
       "param_max_features                                                    5\n",
       "param_n_estimators                                                  100\n",
       "params                {'max_depth': 20, 'max_features': 5, 'n_estima...\n",
       "split0_test_score                                              0.761097\n",
       "split1_test_score                                              0.806396\n",
       "split2_test_score                                              0.816932\n",
       "split3_test_score                                              0.821997\n",
       "split4_test_score                                              0.866625\n",
       "mean_test_score                                                0.814609\n",
       "std_test_score                                                 0.033754\n",
       "rank_test_score                                                      16\n",
       "split0_train_score                                             0.976053\n",
       "split1_train_score                                             0.971612\n",
       "split2_train_score                                             0.972339\n",
       "split3_train_score                                             0.974092\n",
       "split4_train_score                                              0.97256\n",
       "mean_train_score                                               0.973331\n",
       "std_train_score                                                0.001582\n",
       "Name: 6, dtype: object"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_diff = np.abs(df.mean_test_score.values-df.mean_train_score.values)\n",
    "min_index = np.argmin(df.mean_test_score.values-df.mean_train_score.values)\n",
    "df.iloc[min_index,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7942d09f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 9.08 s\n",
      "Wall time: 22.8 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "5 fits failed out of a total of 40.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "joblib.externals.loky.process_executor._RemoteTraceback: \n",
      "\"\"\"\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 436, in _process_worker\n",
      "    r = call_item()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 288, in __call__\n",
      "    return self.fn(*self.args, **self.kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 595, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 216, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 185, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1315, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 250, in fit\n",
      "    raise ValueError(\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\"\"\"\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 450, in fit\n",
      "    trees = Parallel(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1056, in __call__\n",
      "    self.retrieve()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 935, in retrieve\n",
      "    self._output.extend(job.get(timeout=self.timeout))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 542, in wrap_future_result\n",
      "    return future.result(timeout=timeout)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\concurrent\\futures\\_base.py\", line 446, in result\n",
      "    return self.__get_result()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\concurrent\\futures\\_base.py\", line 391, in __get_result\n",
      "    raise self._exception\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan 0.80492684 0.7904174  0.77902454 0.77065106 0.75537841\n",
      " 0.74667326 0.73282777]\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the train scores are non-finite: [       nan 0.9228     0.88759769 0.86010642 0.84138321 0.81792756\n",
      " 0.80465506 0.78690334]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=RandomForestRegressor(max_depth=100, max_features=5,\n",
       "                                             n_jobs=-1, oob_score=True,\n",
       "                                             random_state=144),\n",
       "             param_grid={'min_samples_split': array([ 1,  6, 11, 16, 21, 26, 31, 36])},\n",
       "             return_train_score=True)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_depth     = 100\n",
    "max_features  = 5\n",
    "max_estimator = 100\n",
    "\n",
    "random_forest_model.set_params(n_jobs = -1,oob_score = True, random_state = 144, max_depth = max_depth,\n",
    "                              max_features = max_features, n_estimators = max_estimator)\n",
    "\n",
    "sample_split = np.arange(1,40,5)\n",
    "\n",
    "random_forest_params = {'min_samples_split':sample_split}\n",
    "grid = GridSearchCV(random_forest_model,random_forest_params,cv=5,return_train_score=True)\n",
    "%time grid.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "aa1e3d7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['mean_fit_time', 'std_fit_time', 'mean_score_time', 'std_score_time',\n",
       "       'param_min_samples_split', 'params', 'split0_test_score',\n",
       "       'split1_test_score', 'split2_test_score', 'split3_test_score',\n",
       "       'split4_test_score', 'mean_test_score', 'std_test_score',\n",
       "       'rank_test_score', 'split0_train_score', 'split1_train_score',\n",
       "       'split2_train_score', 'split3_train_score', 'split4_train_score',\n",
       "       'mean_train_score', 'std_train_score'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bd0482a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_min_samples_split</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>0.804927</td>\n",
       "      <td>0.922800</td>\n",
       "      <td>0.033737</td>\n",
       "      <td>0.002090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>0.790417</td>\n",
       "      <td>0.887598</td>\n",
       "      <td>0.035363</td>\n",
       "      <td>0.003530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16</td>\n",
       "      <td>0.779025</td>\n",
       "      <td>0.860106</td>\n",
       "      <td>0.031914</td>\n",
       "      <td>0.007801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21</td>\n",
       "      <td>0.770651</td>\n",
       "      <td>0.841383</td>\n",
       "      <td>0.035122</td>\n",
       "      <td>0.003268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>26</td>\n",
       "      <td>0.755378</td>\n",
       "      <td>0.817928</td>\n",
       "      <td>0.034518</td>\n",
       "      <td>0.005437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>31</td>\n",
       "      <td>0.746673</td>\n",
       "      <td>0.804655</td>\n",
       "      <td>0.033233</td>\n",
       "      <td>0.007477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>36</td>\n",
       "      <td>0.732828</td>\n",
       "      <td>0.786903</td>\n",
       "      <td>0.033503</td>\n",
       "      <td>0.008063</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  param_min_samples_split  mean_test_score  mean_train_score  std_test_score  \\\n",
       "0                       1              NaN               NaN             NaN   \n",
       "1                       6         0.804927          0.922800        0.033737   \n",
       "2                      11         0.790417          0.887598        0.035363   \n",
       "3                      16         0.779025          0.860106        0.031914   \n",
       "4                      21         0.770651          0.841383        0.035122   \n",
       "5                      26         0.755378          0.817928        0.034518   \n",
       "6                      31         0.746673          0.804655        0.033233   \n",
       "7                      36         0.732828          0.786903        0.033503   \n",
       "\n",
       "   std_train_score  \n",
       "0              NaN  \n",
       "1         0.002090  \n",
       "2         0.003530  \n",
       "3         0.007801  \n",
       "4         0.003268  \n",
       "5         0.005437  \n",
       "6         0.007477  \n",
       "7         0.008063  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(grid.cv_results_)\n",
    "df.loc[:,['param_min_samples_split','mean_test_score','mean_train_score','std_test_score',\n",
    "          'std_train_score']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "811a5da0",
   "metadata": {},
   "source": [
    "Based on the above observation, I can conclude that \"min sample per split\" plays a critical role for overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8de88e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bf3ebd6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest_model.set_params(n_jobs = -1,oob_score = True, random_state = 144)\n",
    "\n",
    "depth_list = np.arange(10,40,10)\n",
    "estimator_list = [int(10**i) for i in np.arange(2,4,1)]\n",
    "feature_list = np.arange(5,20,5)\n",
    "sample_split = np.arange(1,40,5)\n",
    "min_samples_leaf = np.arange(5,40,5)\n",
    "\n",
    "random_forest_params = {'max_depth':depth_list,'max_features':feature_list,'n_estimators':estimator_list,\n",
    "                        'min_samples_split':sample_split,'min_samples_leaf':min_samples_leaf}\n",
    "grid = GridSearchCV(random_forest_model,random_forest_params,cv=5,return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fe5114dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 55min 29s\n",
      "Wall time: 1h 27min 44s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=RandomForestRegressor(max_depth=100, max_features=5,\n",
       "                                             n_jobs=-1, oob_score=True,\n",
       "                                             random_state=144),\n",
       "             param_grid={'max_depth': array([10, 20, 30]),\n",
       "                         'max_features': array([ 5, 10, 15]),\n",
       "                         'min_samples_leaf': array([ 5, 10, 15, 20, 25, 30, 35]),\n",
       "                         'min_samples_split': array([ 1,  6, 11, 16, 21, 26, 31, 36]),\n",
       "                         'n_estimators': [100, 1000]},\n",
       "             return_train_score=True)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time grid.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "24e020f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(grid.cv_results_).to_csv('GridSearchResultFull.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a099540e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['mean_fit_time', 'std_fit_time', 'mean_score_time', 'std_score_time',\n",
       "       'param_max_depth', 'param_max_features', 'param_min_samples_leaf',\n",
       "       'param_min_samples_split', 'param_n_estimators', 'params',\n",
       "       'split0_test_score', 'split1_test_score', 'split2_test_score',\n",
       "       'split3_test_score', 'split4_test_score', 'mean_test_score',\n",
       "       'std_test_score', 'rank_test_score', 'split0_train_score',\n",
       "       'split1_train_score', 'split2_train_score', 'split3_train_score',\n",
       "       'split4_train_score', 'mean_train_score', 'std_train_score'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(grid.cv_results_).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e655233c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_max_features</th>\n",
       "      <th>param_min_samples_leaf</th>\n",
       "      <th>param_min_samples_split</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>100</td>\n",
       "      <td>0.774589</td>\n",
       "      <td>0.728419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.777718</td>\n",
       "      <td>0.728014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>100</td>\n",
       "      <td>0.771909</td>\n",
       "      <td>0.725699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1003</th>\n",
       "      <td>30</td>\n",
       "      <td>15</td>\n",
       "      <td>35</td>\n",
       "      <td>26</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.719794</td>\n",
       "      <td>0.703115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004</th>\n",
       "      <td>30</td>\n",
       "      <td>15</td>\n",
       "      <td>35</td>\n",
       "      <td>31</td>\n",
       "      <td>100</td>\n",
       "      <td>0.722562</td>\n",
       "      <td>0.706230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1005</th>\n",
       "      <td>30</td>\n",
       "      <td>15</td>\n",
       "      <td>35</td>\n",
       "      <td>31</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.719794</td>\n",
       "      <td>0.703115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1006</th>\n",
       "      <td>30</td>\n",
       "      <td>15</td>\n",
       "      <td>35</td>\n",
       "      <td>36</td>\n",
       "      <td>100</td>\n",
       "      <td>0.722562</td>\n",
       "      <td>0.706230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1007</th>\n",
       "      <td>30</td>\n",
       "      <td>15</td>\n",
       "      <td>35</td>\n",
       "      <td>36</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.719794</td>\n",
       "      <td>0.703115</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1008 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     param_max_depth param_max_features param_min_samples_leaf  \\\n",
       "0                 10                  5                      5   \n",
       "1                 10                  5                      5   \n",
       "2                 10                  5                      5   \n",
       "3                 10                  5                      5   \n",
       "4                 10                  5                      5   \n",
       "...              ...                ...                    ...   \n",
       "1003              30                 15                     35   \n",
       "1004              30                 15                     35   \n",
       "1005              30                 15                     35   \n",
       "1006              30                 15                     35   \n",
       "1007              30                 15                     35   \n",
       "\n",
       "     param_min_samples_split param_n_estimators  mean_train_score  \\\n",
       "0                          1                100               NaN   \n",
       "1                          1               1000               NaN   \n",
       "2                          6                100          0.774589   \n",
       "3                          6               1000          0.777718   \n",
       "4                         11                100          0.771909   \n",
       "...                      ...                ...               ...   \n",
       "1003                      26               1000          0.719794   \n",
       "1004                      31                100          0.722562   \n",
       "1005                      31               1000          0.719794   \n",
       "1006                      36                100          0.722562   \n",
       "1007                      36               1000          0.719794   \n",
       "\n",
       "      mean_test_score  \n",
       "0                 NaN  \n",
       "1                 NaN  \n",
       "2            0.728419  \n",
       "3            0.728014  \n",
       "4            0.725699  \n",
       "...               ...  \n",
       "1003         0.703115  \n",
       "1004         0.706230  \n",
       "1005         0.703115  \n",
       "1006         0.706230  \n",
       "1007         0.703115  \n",
       "\n",
       "[1008 rows x 7 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(grid.cv_results_).loc[:,['param_max_depth','param_max_features','param_min_samples_leaf',\n",
    "                                     'param_min_samples_split','param_n_estimators','mean_train_score','mean_test_score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "475d00ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8825426153267039\n",
      "0.8210643754367337\n"
     ]
    }
   ],
   "source": [
    "print(np.max(pd.DataFrame(grid.cv_results_).loc[:,'mean_train_score']))\n",
    "print(np.max(pd.DataFrame(grid.cv_results_).loc[:,'mean_test_score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9b651818",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8825426153267039nan\n",
      "0.8210643754367337nan\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(grid.cv_results_)\n",
    "index_max_train = np.argmax(df.loc[:,'mean_train_score'].values)\n",
    "index_max_test  = np.argmax(df.loc[:,'mean_test_score'].values)\n",
    "print(str(np.max(df.loc[:,'mean_train_score'])) + str(df.loc[index_max_train,'mean_test_score']))\n",
    "print(str(np.max(df.loc[:,'mean_test_score'])) + str(df.loc[index_max_test,'mean_train_score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873ffb0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_feature_importance = zip(X_train.columns,grid.best_estimator_.feature_importances_)\n",
    "grid_feature_importance = sorted(grid_feature_importance,reverse=True,key = lambda x : x[1])\n",
    "pd.DataFrame(grid_feature_importance,columns=['Feature','Importance']).to_csv('GridsearchFeatureImportance.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2722b0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(grid_feature_importance,columns=['Feature','Importance']).iloc[1:10,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3508b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(grid_feature_importance,columns=['Feature','Importance'])\n",
    "feature_picked = df.loc[df['Importance'] > 0.02,'Feature'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2c1dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_picked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81bd7682",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputation_error = pd.read_csv('KNNImputation.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50e6249",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "for ifeature in feature_picked:\n",
    "    try:\n",
    "        plt.plot(imputation_error.index.values,imputation_error.loc[:,ifeature].values,label = ifeature)\n",
    "    except:\n",
    "        continue\n",
    "ax = plt.gca()\n",
    "ax.set_xticks(np.arange(1, max(imputation_error.index.values),2),fontsize = 18)\n",
    "ax.set_yticks(np.arange(-40, 81,20),fontsize = 18)\n",
    "plt.grid()\n",
    "plt.xlabel('# of neighborhoods',fontsize = 24)\n",
    "plt.ylabel('Accuracy',fontsize = 24)\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98645430",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.best_estimator_.score(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e5c387",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.best_estimator_.score(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a62a33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac9ab3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_mode_vif = RandomForestRegressor()\n",
    "tree_mode_vif.set_params(max_depth = 20, max_features = 15, n_estimators = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878950e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "vif_randomForest = {}\n",
    "for ifeature in X_train.columns:\n",
    "    X_temp = X_train.drop(ifeature,axis=1)\n",
    "    Y_temp = X_train.loc[:,ifeature]\n",
    "    tree_mode_vif.fit(X_temp,Y_temp)\n",
    "    vif_randomForest[ifeature] = 1/(1 - tree_mode_vif.score(X_temp, Y_temp)**2 + 0.0001)\n",
    "    #print('Size of data are :' + str(X_temp.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454af6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "ax = plt.gca()\n",
    "plt.bar(list(vif_randomForest.keys()),list(vif_randomForest.values()))\n",
    "plt.xlabel('Feature Name :')\n",
    "plt.ylabel('VIF')\n",
    "ax.tick_params(rotation=90.0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b711bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "val = list(vif_randomForest.values())\n",
    "key = list(vif_randomForest.keys())\n",
    "test_features = [key[i] for i in range(len(val)) if val[i] > 50.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754908f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "key[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "256d7b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grid.best_estimator_.score(X_test,Y_test))\n",
    "print(grid.best_estimator_.score(X_train,Y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98a3e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 50\n",
    "val = list(vif_randomForest.values())\n",
    "key = list(vif_randomForest.keys())\n",
    "test_features = [key[i] for i in range(len(val)) if val[i] > threshold]\n",
    "\n",
    "X_train_vif = X_train.drop(test_features,axis=1)\n",
    "X_test_vif = X_test.drop(test_features,axis=1)\n",
    "\n",
    "%time grid.fit(X_train_vif,Y_train)\n",
    "\n",
    "print(grid.best_estimator_.score(X_test_vif,Y_test))\n",
    "print(grid.best_estimator_.score(X_train_vif,Y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92cd0bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(grid.cv_results_)\n",
    "np.min(df.mean_train_score.values-df.mean_test_score.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b813e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_feature = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f39dc41",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ith in np.arange(10,10000,50):\n",
    "    \n",
    "    val = list(vif_randomForest.values())\n",
    "    key = list(vif_randomForest.keys())\n",
    "    test_features = [key[i] for i in range(len(val)) if val[i] > ith]\n",
    "    if (len(test_features) == n_feature) :\n",
    "        continue\n",
    "    else:\n",
    "        n_feature = len(test_features)\n",
    "    X_train_vif = X_train.drop(test_features,axis=1)\n",
    "    X_test_vif = X_test.drop(test_features,axis=1)\n",
    "    grid.fit(X_train_vif,Y_train)\n",
    "    df = pd.DataFrame(grid.cv_results_)\n",
    "    min_diff = np.min(df.mean_train_score.values-df.mean_test_score.values)\n",
    "    min_index = np.argmin(df.mean_train_score.values-df.mean_test_score.values)\n",
    "    test_score = df.mean_test_score.values[min_index]\n",
    "    train_score = df.mean_train_score.values[min_index]\n",
    "    print(str(ith) + '/' + str(min_diff) + '/' + str(test_score)+'/'+str(train_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da7d4efa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
